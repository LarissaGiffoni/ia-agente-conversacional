import os
from dotenv import load_dotenv
from google import genai

load_dotenv()

# Cria o client com a chave de API
client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# 1. ğŸ”„ Inicializa o HistÃ³rico de Conversa (Novo)
# Comece com uma instruÃ§Ã£o de sistema para dar contexto Ã  IA
history = [
    {"role": "user", "parts": ["VocÃª Ã© um agente de IA Ãºtil e amigÃ¡vel. Responda de forma concisa e em portuguÃªs."]},
    {"role": "model", "parts": ["Entendido. Como posso ajudar vocÃª hoje?"]}
]

print("ğŸ¤– Agente de IA iniciado! Digite 'sair' para encerrar.\n")

while True:
    user_input = input("VocÃª: ")

    if user_input.lower() == "sair":
        print("ğŸ‘‹ Encerrando agente.")
        break

    try:
        # 2. â• Adiciona a mensagem do usuÃ¡rio ao histÃ³rico ANTES da chamada
        history.append({"role": "user", "parts": [user_input]})

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            # 3. ğŸ§  Passa o histÃ³rico completo para a IA
            contents=history 
        )
        
        # 4. â• Adiciona a resposta da IA ao histÃ³rico DEPOIS da chamada
        history.append({"role": "model", "parts": [response.text]})

        print("\nIA:", response.text, "\n")
        
    except Exception as e:
        print(f"\nğŸš« Erro ao gerar conteÃºdo: {e}\n")